{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d42a71d",
   "metadata": {},
   "source": [
    "El dataset PadChest que vamos a usar se descarga desde https://bimcv.cipf.es/bimcv-projects/padchest/ cualquier persona lo puede usar pero se han de aceptar las condiciones. Para facilitar la descarga y organización de las imágenes dejo a continuación las funciones usadas.\n",
    "\n",
    "Una vez se hayan aceptado las condiciones y descargado todos los archivos comprimidos, guardaremos todas las imagenes en la carpeta 'extracted_files' y organizaremos las imagenes por clases con los nombres 'normal' y 'lung_metastasis' con las imagenes correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9df570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una carpeta para cada clase\n",
    "lung_metastasis_dir = os.path.join(base_path, 'lung_metastasis')\n",
    "normal_dir = os.path.join(base_path, 'normal')\n",
    "\n",
    "# Aseguramos que dichas carpetas existen\n",
    "os.makedirs(lung_metastasis_dir, exist_ok=True)\n",
    "os.makedirs(normal_dir, exist_ok=True)\n",
    "\n",
    "# Función para procesar cada archivo ZIP\n",
    "def process_zip_file(zip_name):\n",
    "    zip_path = os.path.join(zip_folder, f'{zip_name}.zip')\n",
    "    extract_dir = os.path.join(base_path, 'extracted_files')\n",
    "\n",
    "    # Extraer el ZIP\n",
    "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(extract_dir)\n",
    "        print(f\"Archivos extraídos en el directorio: {extract_dir}\")\n",
    "\n",
    "    # Filtro para seleccionar las imagenes que son normales o con metastasis.\n",
    "    df_filtrado = df[df['Labels'].apply(lambda x: 'lung metastasis' in x or 'normal' in x if pd.notna(x) else False)]\n",
    "\n",
    "    # Mover imágenes filtradas a las carpetas correspondientes\n",
    "    for index, row in df_filtrado.iterrows():\n",
    "        source_path = os.path.join(extract_dir, row['ImageID'])\n",
    "        if 'lung metastasis' in row['Labels']:\n",
    "            dest_path = os.path.join(lung_metastasis_dir, row['ImageID'])\n",
    "        elif 'normal' in row['Labels']:\n",
    "            dest_path = os.path.join(normal_dir, row['ImageID'])\n",
    "\n",
    "        if os.path.exists(source_path):\n",
    "            shutil.move(source_path, dest_path)\n",
    "        else:\n",
    "            print(f\"Archivo no encontrado: {source_path}\")\n",
    "\n",
    "# Iterar sobre cada archivo ZIP en la lista\n",
    "for zip_name in zip_names:\n",
    "    process_zip_file(zip_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6c7fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejemplo de alamcenamiento de las imagenes desde los archivos comprimidos\n",
    "\n",
    "#zip_names = ['1','2','3']\n",
    "#Ruta donde se almacenarán las imagenes\n",
    "#base_path = 'D:\\\\Datos Usuario\\\\Desktop\\\\data\\\\Año 2.2\\\\TFM\\\\Imagenes'\n",
    "\n",
    "#Ruta donde se guardan los archivos comprimidos de donde se van a extraer las imagenes\n",
    "#zip_folder = 'D:\\\\Datos Usuario\\\\Desktop\\\\data\\\\Año 2.2\\\\TFM\\\\Imagenes'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb662fe",
   "metadata": {},
   "source": [
    "Una vez descargadas las almacenamos en un directorio para separarlas en dos conjuntos, uno de entrenamiento y otro de validacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec43ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear los directorios si no existen\n",
    "os.makedirs('data/normales', exist_ok=True)\n",
    "os.makedirs('data/metastasis', exist_ok=True)\n",
    "\n",
    "# Mover imágenes a la nueva estructura\n",
    "for filename in os.listdir('normal_redimensionadas'):\n",
    "    shutil.move(f'normal_redimensionadas/{filename}', 'data/normales/')\n",
    "\n",
    "for filename in os.listdir('metastasis_augmented'):\n",
    "    shutil.move(f'metastasis_augmented/{filename}', 'data/metastasis/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f4972f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rutas a las carpetas originales\n",
    "dir_normales = 'data/normales'\n",
    "dir_metastasis = 'data/metastasis'\n",
    "\n",
    "# Rutas a las carpetas de destino\n",
    "train_normales = 'data/train/normales'\n",
    "train_metastasis = 'data/train/metastasis'\n",
    "val_normales = 'data/val/normales'\n",
    "val_metastasis = 'data/val/metastasis'\n",
    "\n",
    "# Crear las carpetas si no existen\n",
    "os.makedirs(train_normales, exist_ok=True)\n",
    "os.makedirs(train_metastasis, exist_ok=True)\n",
    "os.makedirs(val_normales, exist_ok=True)\n",
    "os.makedirs(val_metastasis, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d6f07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_and_copy_data(source, train_dir, val_dir, test_size=0.2):\n",
    "    # Lista todos los archivos en la carpeta fuente\n",
    "    files = [f for f in os.listdir(source) if os.path.isfile(os.path.join(source, f))]\n",
    "\n",
    "    # Divide los archivos en entrenamiento y validación\n",
    "    train_files, val_files = train_test_split(files, test_size=test_size, random_state=42)\n",
    "\n",
    "    # Copia los archivos a las carpetas de entrenamiento y validación\n",
    "    for f in train_files:\n",
    "        shutil.copy(os.path.join(source, f), os.path.join(train_dir, f))\n",
    "    for f in val_files:\n",
    "        shutil.copy(os.path.join(source, f), os.path.join(val_dir, f))\n",
    "\n",
    "# Aplicar la función a las carpetas de normales y metástasis\n",
    "#split_and_copy_data(dir_normales, train_normales, val_normales)\n",
    "#split_and_copy_data(dir_metastasis, train_metastasis, val_metastasis)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58735421",
   "metadata": {},
   "source": [
    "Comprobamos que la division se ha realizado de forma correcta. Esta funcion realiza el recuento por clase del numero de imagenes en los conjuntos train y val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aef3279",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_images(directory):\n",
    "    categories = os.listdir(directory)\n",
    "    counts = {}\n",
    "    for category in categories:\n",
    "        path = os.path.join(directory, category)\n",
    "        if os.path.isdir(path):  # Asegura que solo cuenta directorios (clases)\n",
    "            counts[category] = len(os.listdir(path))\n",
    "    return counts\n",
    "\n",
    "# Conteo de imágenes en el directorio de entrenamiento y validación\n",
    "train_counts = count_images('data/train')\n",
    "val_counts = count_images('data/val')\n",
    "\n",
    "print(\"Entrenamiento:\", train_counts)\n",
    "print(\"Validación:\", val_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781215af",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_images(source_directory, target_directory):\n",
    "    if not os.path.exists(target_directory):\n",
    "        os.makedirs(target_directory)\n",
    "\n",
    "    image_count = 0\n",
    "\n",
    "    for filename in os.listdir(source_directory):\n",
    "        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(source_directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "            if image is not None:\n",
    "                # Lista de imágenes para incluir la original y sus transformaciones\n",
    "                images = [image]\n",
    "\n",
    "                # Aplicar rotación de 90 grados\n",
    "                rotated_90 = cv2.rotate(image, cv2.ROTATE_90_CLOCKWISE)\n",
    "                images.append(rotated_90)\n",
    "\n",
    "                # Aplicar rotación de 180 grados\n",
    "                rotated_180 = cv2.rotate(image, cv2.ROTATE_180)\n",
    "                images.append(rotated_180)\n",
    "\n",
    "                # Aplicar rotación de 270 grados\n",
    "                rotated_270 = cv2.rotate(image, cv2.ROTATE_90_COUNTERCLOCKWISE)\n",
    "                images.append(rotated_270)\n",
    "\n",
    "                # Aplicar volteo horizontal\n",
    "                flipped_horizontal = cv2.flip(image, 1)\n",
    "                images.append(flipped_horizontal)\n",
    "\n",
    "                # Aplicar volteo vertical\n",
    "                flipped_vertical = cv2.flip(image, 0)\n",
    "                images.append(flipped_vertical)\n",
    "\n",
    "                # Guardar todas las imágenes transformadas\n",
    "                for img in images:\n",
    "                    output_filename = f\"{filename.split('.')[0]}_aug_{image_count}.{filename.split('.')[-1]}\"\n",
    "                    output_path = os.path.join(target_directory, output_filename)\n",
    "                    cv2.imwrite(output_path, img)\n",
    "                    image_count += 1\n",
    "    print(f\"Total de imágenes creadas: {image_count}\")\n",
    "    \n",
    "# Directorio origen\n",
    "# source_directory = \"Raw/train/metastasis\"\n",
    "# Directorio destino\n",
    "# target_directory = \"Raw/train/metastasis_augmented\"\n",
    "\n",
    "# augment_images(source_directory, target_directory)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
